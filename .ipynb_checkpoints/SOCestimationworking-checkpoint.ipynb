{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6613aed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-26424854813a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#Import Libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow.keras import Input\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acddc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads matlab files data into a python dict\n",
    "mat_data = loadmat('.../TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs.mat')\n",
    "\n",
    "#Test data set\n",
    "test_data = loadmat('.../04_TEST_LGHG2@25degC_Norm_(05_Inputs).mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778147a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the first 3 rows (Voltage, Current, Temp) and 100000 columns from the \"X\" key\n",
    "x_train = mat_data[\"X\"][:3,:600000] \n",
    "# extracts the first 100000 columns from the \"Y\" (SOC) key\n",
    "y_train = mat_data[\"Y\"][:1,:600000] \n",
    "\n",
    "#Create the x_test and y_test data sets\n",
    "x_test = test_data[\"X\"][:3,:40000]\n",
    "y_test = test_data[\"Y\"][:1,:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flips columns and rows so data is proper shape, have the same # of input features\n",
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28891244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the x_train and y_train to numpy arrays\n",
    "x_train, y_train = np.array(x_train),np.array(y_train)\n",
    "x_test, y_test = np.array(x_test),np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b622c7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape the data\n",
    "x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_responses = 1\n",
    "num_features = 3\n",
    "num_hidden_units = 10\n",
    "epochs = 10000\n",
    "batch_size = x_test.shape[0]\n",
    "learn_rate_drop_period = 2000\n",
    "LearningRate = 0.01\n",
    "learn_rate_drop_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the LSTM model \n",
    "model = Sequential()\n",
    "# model.add(LSTM(num_hidden_units, input_shape=(x_train.shape[1],1), stateful=False,return_sequences=False))\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, x_train.shape[1],1), stateful=True,return_sequences=False))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0cbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch % learn_rate_drop_period == 0 and epoch:\n",
    "        return lr * learn_rate_drop_factor\n",
    "    else:\n",
    "        return lr\n",
    "\n",
    "#Define the learning rate scheduler callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "#Compile the model with a learning rate scheduler\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LearningRate), loss='mean_squared_error')\n",
    "\n",
    "#Train the model\n",
    "model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions Stateful = True\n",
    "trainPredict = model.predict(x_train, batch_size=batch_size)\n",
    "# model.reset_states()\n",
    "testPredict = model.predict(x_test, batch_size=batch_size)\n",
    "# model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19494104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the root mean squared error (RMSE)\n",
    "rmse_train=np.sqrt(np.mean(((trainPredict- y_train)**2)))*100\n",
    "rmse_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7049393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the root mean squared error (RMSE)\n",
    "rmse_test=np.sqrt(np.mean(((testPredict- y_test)**2)))*100\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c75a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "# Plot the predictions\n",
    "plt.plot(testPredict, label=\"Predictions\")\n",
    "# Plot the true values\n",
    "plt.plot(y_test, label=\"Objective\")\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd21d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('LSTM_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25476781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cb8dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
