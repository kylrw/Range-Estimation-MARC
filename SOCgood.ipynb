{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c7d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.signal import find_peaks\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e6b399",
   "metadata": {},
   "source": [
    "Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f219e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(x: np.ndarray, y: np.ndarray) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Splits the input x and y arrays on the first axis if the y value increases by more than 0.75\n",
    "    \"\"\"\n",
    "    x = x.T[:, :3]\n",
    "    y = y.T\n",
    "    chunks = []\n",
    "    chunk_x = []\n",
    "    chunk_y = []\n",
    "    for i in range(x.shape[0]):\n",
    "        if i == 0:\n",
    "            chunk_x.append(x[i])\n",
    "            chunk_y.append(y[i])\n",
    "        elif i > 0 and y[i] - y[i - 1] > 0.5 and y[i] > 0.8:\n",
    "            chunks.append((np.array(chunk_x), np.array(chunk_y)))\n",
    "            chunk_x = []\n",
    "            chunk_y = []\n",
    "        else:\n",
    "            chunk_x.append(x[i])\n",
    "            chunk_y.append(y[i])\n",
    "\n",
    "    \n",
    "    chunks.append((np.array(chunk_x), np.array(chunk_y)))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843964ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\\1\\01.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\02.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\03.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\04.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\05.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\06.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\07.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\08.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\09.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n",
      "Data\\1\\10.0__Chopped_(Panasonic_7Features_SingleFile_n20_to_25degC)_V2.mat\n"
     ]
    }
   ],
   "source": [
    "#grabs all .mat files from Data/New MATLAB Data\n",
    "mat_files = list(Path(\"Data/1\").glob(\"*.mat\"))\n",
    "for mat_file in mat_files:\n",
    "    print(mat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf90e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabs all .mat files from Data/New MATLAB Data\n",
    "mat_files = list(Path(\"Data/1\").glob(\"*.mat\"))\n",
    "\n",
    "chunks = []\n",
    "for mat_file in mat_files:\n",
    "    mat_data = loadmat(mat_file)\n",
    "    chunks.extend(get_chunks(mat_data[\"X\"], mat_data[\"Y\"]))\n",
    "\n",
    "# joins chunks thats initial value is < 0.5 and their previous chunk\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if chunk[1][0] < 0.5 and i > 0:\n",
    "        chunks[i - 1] = (np.concatenate((chunks[i - 1][0], chunk[0])), np.concatenate((chunks[i - 1][1], chunk[1])))\n",
    "        del chunks[i]\n",
    "\n",
    "# joins chunks thats final value is > 0.5 and their following chunk\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if chunk[1][-1] > 0.5 and i < len(chunks) - 1:\n",
    "        chunks[i + 1] = (np.concatenate((chunk[0], chunks[i + 1][0])), np.concatenate((chunk[1], chunks[i + 1][1])))\n",
    "        del chunks[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd30623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "#prints the number of chunks\n",
    "print(len(chunks))\n",
    "all_chunks = chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c929ff0",
   "metadata": {},
   "source": [
    "Define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d30a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 16\n",
    "        self.num_layers = 1\n",
    "        self.lstm = nn.LSTM(3, 16, 1, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(16)\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # out = self.fc1(x)\n",
    "        out = x\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.ln(out)\n",
    "        out = self.fc2(out)\n",
    "        out = torch.clip(out, 0, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f01768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab7b3604",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a2789a50bcaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_chunks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for chunk in all_chunks:\n",
    "    for (x,y) in chunk:\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19b495c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6e039a991834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_chunks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(500):\n",
    "    loss = 0\n",
    "    for chunk in all_chunks:\n",
    "        for (inputs, targets) in chunk:\n",
    "            inputs = torch.from_numpy((inputs - means) / stds).float().unsqueeze(0).cuda()\n",
    "            targets = torch.from_numpy(targets).float().unsqueeze(0).cuda()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss += criterion(outputs, targets) ** 0.5\n",
    "    loss /= 29.\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
